{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "different-demographic",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This part consist of data reading, analyzing, cleaning and saving for further work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the schema for dataset\n",
    "schema = StructType([ \\\n",
    "    StructField(\"event_time\",TimestampType(),True),\\\n",
    "    StructField(\"event_type\",StringType(),False),\\\n",
    "    StructField(\"product_id\",IntegerType(),True),\\\n",
    "    StructField(\"category_id\", LongType(), True),\\\n",
    "    StructField(\"category_code\", StringType(), True),\\\n",
    "    StructField(\"brand\", StringType(), True),\\\n",
    "    StructField(\"price\", DoubleType(), True),\\\n",
    "    StructField(\"user_id\", IntegerType(), True),\\\n",
    "    StructField(\"user_session\", StringType(), True),\\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df=spark.read.csv('local_part.csv', schema=schema, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unic users\n",
    "df_data.groupBy('user_id').count().distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users events count\n",
    "df.groupBy('user_id').count().orderBy('count',ascending=False).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brands events count\n",
    "df.groupBy('brand').count().orderBy('count',ascending=False).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events count\n",
    "df.groupBy('event_type').count().orderBy('count',ascending=False).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert event_type to raiting such us purchase = 1, view and chart = 0\n",
    "# so if user bought item, he \"rated\" it\n",
    "dictionary = {\"purchase\": \"1\", \"view\": \"0\", \"cart\": \"0\"}\n",
    "df2 = df.na.replace(dictionary,\"event_type\")\n",
    "#df2.show()\n",
    "\n",
    "# cast to integer\n",
    "df_data = df2.select(df2[\"event_type\"].cast(IntegerType()), df2[\"user_id\"], df2[\"product_id\"]) \n",
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-graph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-worse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
